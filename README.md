# EXP-3-PROMPT-ENGINEERING-

## Aim: 
Evaluation of 2024 Prompting Tools Across Diverse AI Platforms: 
ChatGPT, Claude, Bard, Cohere Command, and Meta
Experiment:
Within a specific use case (e.g., summarizing text, answering technical questions), compare the performance, user experience, and response quality of prompting tools across these different AI platforms.

## Algorithm:
1. Define tasks & metrics (faithfulness, format adherence, citations, latency, cost).
2. Prepare standardized inputs & prompts (same article, same technical question).
3. Run each model with fixed settings; log outputs and metadata.
4. Score with a rubric; verify claims/citations; compute aggregate stats.
5. Synthesize findings into a structured report with summaries, templates, and recommendations.

## Prompt:
Evaluation of 2024 Prompting Tools Across Diverse AI Platforms to make a report on this topic needs at least 7 pages

## Output
![lab 3_page-0001](https://github.com/user-attachments/assets/a9624f40-1baa-4e50-8581-d4605c99bbca)
![lab 3_page-0002](https://github.com/user-attachments/assets/3640fdca-6762-4eec-9541-4514c0a1e8bd)

[lab 3_page-0003](https://github.com/user-attachments/assets/2e3c8c31-0f33-4ffc-91cd-613489e1e825)
8dfb9)
![lab 3_page-0004](https://github.com/user-attachments/assets/595b12d6-be47-4a88-a86f-3b981201fa47)
![lab 3_page-0005](https://github.com/user-attachments/assets/a1424ce9-28b5-46a2-841a-9cfbd30b6a7f)
![lab 3_page-0006](https://github.com/user-attachments/assets/40100376-5611-48fe-b54a-688de90b958b)
![lab 3_page-0007](https://github.com/user-attachments/assets/77a67111-a897-485b-a953-719c53ce7a32)
![lab 3_page-0008](https://github.com/user-attachments/assets/800dbc0b-dcd9-4836-8a9f-56051e8cc86c)

## Result
The report was successfully submitted.
